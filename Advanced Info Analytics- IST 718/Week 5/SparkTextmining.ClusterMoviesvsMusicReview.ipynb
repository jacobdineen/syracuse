{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE BASICS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# USING PYSPARK FOR EASY INTEGRATION\n",
    "import pyspark.sql.types as typ \n",
    "import pyspark.ml.feature as ft\n",
    "# CLASSIFICATION\n",
    "import pyspark.ml.classification as cl\n",
    "import pyspark.sql.functions as func\n",
    "# FOR BUILDING THE FUNCTION ORDER OF FEATURE EXTRACTION TASKS\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml import PipelineModel\n",
    "# FOR CLUSTERING\n",
    "import pyspark.ml.clustering as clus\n",
    "from pyspark.mllib.clustering import LDA, LDAModel\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "import pyspark.ml.evaluation as ev\n",
    "import pyspark.ml.tuning as tune\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTAIN - METHOD FOR ADDING SIMPLE TEXT - IMPORT METHOD FROM CSV BELOW\n",
    "\n",
    "text_data = spark.createDataFrame([\n",
    "    ['''It's more of a therapeutic release than anything else, and if you're in the mood to just release it all with a grin, then Tamborine is crucial'''],\n",
    "    ['''[Ryan] Coogler's overall ambition in crafting a sociologically complex story and presenting it as standard comic book movie fare succeeds: There is nothing common about Black Panther'''],\n",
    "    ['''\"While he may have been brought low as a husband and father, Rock's powers as a comedian have not been diminished'''],\n",
    "    ['''The third full-length solo release for the Long Island singer-songwriter features contributions from Chris Farren, Dan Potthast, PUP, Laura Stevenson, and Antarctigo Vespucci'''],\n",
    "    ['''While that sounds incredibly daunting--and like a really tiring listen--the album’s most impressive trait is that it makes all that vital work feel joyous and communal'''],\n",
    "    ['''Gorgeous and energetic, Jeff’s manifesto in POST- (in parts), especially when we talk about politics, remind me those previous songs that some singers tried to bring along 2017 but could not pass a trusty message. He slayed them. His new record clarify minds and shake the soul with a contagious rhythm all whole the 10 tracks''']\n",
    "], ['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer specifies the patterns the text should be broken into\n",
    "# text is being split by number of spaces\n",
    "\n",
    "tokenizer = ft.RegexTokenizer(\n",
    "    inputCol='documents', \n",
    "    outputCol='input_arr', \n",
    "    pattern='\\s+|[,.\\\"]')\n",
    "\n",
    "stopwords = ft.StopWordsRemover(\n",
    "    inputCol=tokenizer.getOutputCol(), \n",
    "    outputCol='input_stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(input_indexed=SparseVector(105, {0: 2.0, 12: 1.0, 15: 1.0, 34: 1.0, 44: 1.0, 71: 1.0, 77: 1.0, 87: 1.0, 88: 1.0, 94: 1.0})),\n",
       " Row(input_indexed=SparseVector(105, {8: 1.0, 10: 1.0, 23: 1.0, 27: 1.0, 29: 1.0, 33: 1.0, 41: 1.0, 43: 1.0, 47: 1.0, 56: 1.0, 58: 1.0, 59: 1.0, 72: 1.0, 83: 1.0, 89: 1.0, 96: 1.0, 97: 1.0, 103: 1.0, 104: 1.0}))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "stringIndexer = ft.CountVectorizer(\n",
    "    inputCol=stopwords.getOutputCol(), \n",
    "    outputCol=\"input_indexed\")\n",
    "\n",
    "tokenized = stopwords \\\n",
    "    .transform(\n",
    "        tokenizer\\\n",
    "            .transform(text_data)\n",
    "    )\n",
    "    \n",
    "stringIndexer \\\n",
    "    .fit(tokenized)\\\n",
    "    .transform(tokenized)\\\n",
    "    .select('input_indexed')\\\n",
    "    .take(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MODEL - USING LATENT DIRICHLET ALLOCATION\n",
    "clustering = clus.LDA(k=2, optimizer='online', featuresCol=stringIndexer.getOutputCol())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# MODEL - BUILDING THE PIPELINE\n",
    "# 1 - CREATE JUST WORD TOKENS\n",
    "# 2 - REMOVE STOPWORDS\n",
    "# 3 - CREATE INDEX & CLUSTERS\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "        tokenizer, \n",
    "        stopwords,\n",
    "        stringIndexer, \n",
    "        clustering]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(topicDistribution=DenseVector([0.946, 0.054])),\n",
       " Row(topicDistribution=DenseVector([0.1879, 0.8121])),\n",
       " Row(topicDistribution=DenseVector([0.9462, 0.0538])),\n",
       " Row(topicDistribution=DenseVector([0.9652, 0.0348])),\n",
       " Row(topicDistribution=DenseVector([0.0385, 0.9615])),\n",
       " Row(topicDistribution=DenseVector([0.0209, 0.9791]))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# INTERPRET - LOOK AT THE RESULTS OF THE CLUSTERING\n",
    "\n",
    "topics = pipeline \\\n",
    "    .fit(text_data) \\\n",
    "    .transform(text_data)\n",
    "\n",
    "topics.select('topicDistribution').collect()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
